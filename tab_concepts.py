"""
tab_concepts.py â€” Logistic Regression Concepts & Theory
"""
import streamlit as st
import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from tab_explainers import explainer_concepts
from components import (
    render_card, ib, render_ib, fml, bdg, hl, gt, rt2, org, pur,
    lb_t, txt_s, p, steps_html, two_col, three_col, four_col,
    table_html, metric_row, section_heading, stat_box, S, FH, FB, FM, TXT, NO_SEL
)

def _f(t):
    return f'<span style="font-family:{FM};font-size:.83rem;color:#64ffda;-webkit-text-fill-color:#64ffda">{t}</span>'

def tab_concepts():
    render_card("ğŸ¯ Why Logistic Regression? The Problem with OLS for Binary Outcomes",
        p(f'When the dependent variable Y is {hl("binary (0 or 1)")}, OLS regression fails. '
          f'Logistic regression solves this with a bounded, probabilistic model.')
        + three_col(
            ib(f'<span style="color:#dc3545;-webkit-text-fill-color:#dc3545;font-weight:600">âŒ OLS Fails Because:</span><br>'
               + p(f'Predicted values can exceed [0,1]<br>Violates homoscedasticity<br>'
                   f'Residuals non-normal (only 0 or 1)<br>Linear PD model is nonsensical')
               + p(f'{rt2("Example:")} OLS predicts PD = âˆ’0.12 or PD = 1.34 â€” impossible!'), "red"),
            ib(f'<span style="color:#28a745;-webkit-text-fill-color:#28a745;font-weight:600">âœ… Logistic Solves:</span><br>'
               + p(f'Output always bounded in (0,1) â€” valid probability<br>'
                   f'Uses {hl("sigmoid")} to map â„ â†’ (0,1)<br>'
                   f'Estimated via {hl("Maximum Likelihood")}<br>'
                   f'Natural probability interpretation')
               + p(f'{gt("Finance:")} P(Default), P(Fraud), P(Downgrade), P(Approval)'), "green"),
            ib(f'<span style="color:#FFD700;-webkit-text-fill-color:#FFD700;font-weight:600">ğŸ“ˆ Finance Applications:</span><br>'
               + p(f'{bdg("Credit Risk","red")} P(Default) from financials<br>'
                   f'{bdg("Fraud Detection","orange")} P(Fraud transaction)<br>'
                   f'{bdg("Rating Migration","blue")} P(Downgrade)<br>'
                   f'{bdg("M&A","purple")} P(Deal Completion)<br>'
                   f'{bdg("Loan Approval","green")} Binary credit decision'), "gold"),
        )
    )

    render_card("ğŸ“ The Logistic (Sigmoid) Function",
        p(f'The core transformation that maps any real number to a valid probability.')
        + two_col(
            fml("Model:   P(Y=1|X) = 1 / (1 + e^(âˆ’z))\n"
                "where:   z = Î²â‚€ + Î²â‚Xâ‚ + ... + Î²â‚–Xâ‚–\n\n"
                "Log-Odds (Logit): log[P/(1âˆ’P)] = Î²â‚€ + Î²â‚Xâ‚ + ... + Î²â‚–Xâ‚–\n\n"
                "Odds Ratio:  OR = e^Î²_j\n"
                "  OR > 1 â†’ Xâ±¼ increases odds of Y=1\n"
                "  OR < 1 â†’ Xâ±¼ decreases odds of Y=1"),
            ib(f'<span style="color:#FFD700;-webkit-text-fill-color:#FFD700;font-weight:600">Key Properties:</span><br>'
               + p(f'Ïƒ(0) = 0.5 â€” natural decision boundary<br>'
                   f'Ïƒ(z) â†’ 1 as z â†’ +âˆ; Ïƒ(z) â†’ 0 as z â†’ âˆ’âˆ<br>'
                   f'S-shaped, monotonically increasing<br>'
                   f"Ïƒâ€²(z) = Ïƒ(z)(1âˆ’Ïƒ(z)) â€” elegant derivative<br>"
                   f'Inverse of sigmoid = logit function<br>'
                   f'Threshold adjustable for imbalanced data'), "gold"),
        )
    )

    render_card("ğŸ“Š Interactive Sigmoid Explorer",
        ib(f'Adjust Î²â‚€ and Î²â‚ to see how the sigmoid maps X â†’ P(Y=1). '
           f'{hl("Green region")} = predicted positive class. '
           f'{rt2("Red region")} = predicted negative class.', "blue")
    )
    explainer_concepts()
    col1, col2, col3 = st.columns(3)
    b0 = col1.slider("Î²â‚€ (Intercept)", -4.0, 4.0, 0.0, 0.25, key="sig_b0")
    b1 = col2.slider("Î²â‚ (Slope)", -3.0, 3.0, 1.0, 0.25, key="sig_b1")
    threshold = col3.slider("Decision Threshold", 0.10, 0.90, 0.50, 0.05, key="sig_thresh")

    x = np.linspace(-6, 6, 400)
    z = b0 + b1 * x
    prob = 1 / (1 + np.exp(-z))
    log_odds = z  # logit is linear

    fig, axes = plt.subplots(1, 3, figsize=(14, 5), facecolor="#0a1628")

    def _sax(ax):
        ax.set_facecolor("#112240"); ax.tick_params(colors="#8892b0", labelsize=8)
        for sp in ax.spines.values(): sp.set_color("#1e3a5f")
        ax.grid(color="#1e3a5f", alpha=0.35, lw=0.5)

    axes[0].plot(x, prob, color="#FFD700", lw=2.5)
    axes[0].axhline(threshold, color="#dc3545", lw=1.5, ls="--", label=f"Threshold={threshold:.2f}")
    axes[0].axhline(0.5, color="#64ffda", lw=1, ls=":", alpha=0.7)
    axes[0].fill_between(x, prob, threshold, where=(prob > threshold), alpha=0.2, color="#28a745")
    axes[0].fill_between(x, prob, threshold, where=(prob <= threshold), alpha=0.2, color="#dc3545")
    axes[0].set(xlabel="X", ylabel="P(Y=1|X)"); axes[0].set_ylim(-0.05, 1.05)
    axes[0].set_title(f"Sigmoid Ïƒ(Î²â‚€={b0}, Î²â‚={b1})", color="#FFD700", fontsize=10)
    axes[0].legend(facecolor="#112240", labelcolor="#e6f1ff", fontsize=8, edgecolor="#1e3a5f")
    axes[0].xaxis.label.set_color("#8892b0"); axes[0].yaxis.label.set_color("#8892b0")
    _sax(axes[0])

    axes[1].plot(x, log_odds, color="#ADD8E6", lw=2.5)
    axes[1].axhline(0, color="#FFD700", lw=1, ls="--")
    axes[1].set(xlabel="X", ylabel="Log-Odds = Î²â‚€ + Î²â‚X")
    axes[1].set_title("Log-Odds (Linear in X)", color="#FFD700", fontsize=10)
    axes[1].xaxis.label.set_color("#8892b0"); axes[1].yaxis.label.set_color("#8892b0")
    _sax(axes[1])

    for b1v, col in [(-2,"#dc3545"),(-1,"#ff9f43"),(0,"#8892b0"),(1,"#ADD8E6"),(2,"#FFD700")]:
        axes[2].plot(x, 1/(1+np.exp(-(b0+b1v*x))), color=col, lw=1.8, label=f"Î²â‚={b1v}", alpha=0.85)
    axes[2].axhline(0.5, color="#64ffda", lw=1, ls=":", alpha=0.7)
    axes[2].set(xlabel="X", ylabel="P(Y=1|X)")
    axes[2].set_title("Effect of Î²â‚ on Steepness", color="#FFD700", fontsize=10)
    axes[2].legend(facecolor="#112240", labelcolor="#e6f1ff", fontsize=8, edgecolor="#1e3a5f", ncol=2)
    axes[2].xaxis.label.set_color("#8892b0"); axes[2].yaxis.label.set_color("#8892b0")
    _sax(axes[2])

    plt.tight_layout(pad=1.5)
    st.pyplot(fig, use_container_width=True)
    plt.close(fig)

    if b1 != 0:
        boundary = -b0 / b1
        p_at_0 = 1 / (1 + np.exp(-b0))
        st.html(four_col(
            stat_box("Decision Boundary X*", f"{boundary:.3f}", f"P={0.5:.1f} here always", "gold"),
            stat_box("P(Y=1) at X=0", f"{p_at_0:.4f}", "Intercept-driven", "blue"),
            stat_box("Odds Ratio e^Î²â‚", f"{np.exp(b1):.4f}", "Per unit Î”X change", "orange"),
            stat_box("Max Slope â‰ˆ Î²â‚/4", f"{b1/4:.4f}", "At decision boundary", "purple"),
        ))

    render_card("âš– OLS vs Logistic Regression â€” Complete Comparison",
        table_html(
            ["Feature", "OLS Regression", "Logistic Regression"],
            [
                [bdg("Dependent Y","blue"),    txt_s("Continuous âˆˆ (âˆ’âˆ,+âˆ)"),        txt_s("Binary âˆˆ {0,1}")],
                [bdg("Output","gold"),          txt_s("Predicted value Å¶"),            txt_s("Probability P(Y=1|X) âˆˆ (0,1)")],
                [bdg("Link function","purple"), txt_s("Identity: E(Y) = XÎ²"),         txt_s("Logit: log[P/(1âˆ’P)] = XÎ²")],
                [bdg("Estimation","orange"),    txt_s("OLS â€” Minimise Î£(Yâˆ’Å¶)Â²"),     txt_s("MLE â€” Maximise Î£log L(Î²)")],
                [bdg("Error dist.","red"),      txt_s("Normal (CLRM assumption)"),    txt_s("Bernoulli â€” not normal")],
                [bdg("Goodness of fit","green"),txt_s("RÂ², Adj RÂ², F-test"),          txt_s("McFadden RÂ², AUC-ROC, Log-Loss")],
                [bdg("Coefficients","blue"),    txt_s("Direct Î”Y per unit Î”X"),       txt_s("Log-odds change; exp(Î²) = OR")],
                [bdg("Inference","purple"),     txt_s("t-test, F-test"),              txt_s("Wald test, LR test, Score test")],
                [bdg("Finance use","orange"),   txt_s("Return forecast, factor models"),txt_s("PD, fraud, rating migration")],
            ]
        )
    )

    render_card("ğŸ”§ Maximum Likelihood Estimation (MLE)",
        p(f'Coefficients found by {hl("maximising the log-likelihood")} â€” making observed data most probable.')
        + steps_html([
            ("Log-Likelihood", "â„“(Î²) = Î£áµ¢ [yáµ¢ log(páµ¢) + (1âˆ’yáµ¢) log(1âˆ’páµ¢)]  where páµ¢ = Ïƒ(Xáµ¢Î²)"),
            ("Optimisation", "Newton-Raphson / Fisher Scoring: Î²_new = Î²_old âˆ’ Hâ»Â¹âˆ‡â„“ (Hessian update)"),
            ("Standard Errors", "SE(Î²Ì‚) = âˆš[diag(âˆ’Hâ»Â¹)] from the Fisher Information Matrix"),
            ("McFadden RÂ²", "ÏÂ² = 1 âˆ’ â„“(Î²)/â„“â‚€  where â„“â‚€ is intercept-only log-likelihood"),
        ])
        + fml("Log-Likelihood:   â„“(Î²) = Î£áµ¢ yáµ¢ log(páµ¢) + (1âˆ’yáµ¢)log(1âˆ’páµ¢)\n"
              "Null LL:          â„“â‚€ = n[pÌ„ log(pÌ„) + (1âˆ’pÌ„)log(1âˆ’pÌ„)]\n"
              "McFadden RÂ²:      ÏÂ² = 1 âˆ’ â„“(Î²)/â„“â‚€    [0.2â€“0.4 = good fit in finance]")
    )

    render_card("ğŸ“‹ Logistic Regression Assumptions",
        two_col(
            ib(f'<span style="color:#28a745;-webkit-text-fill-color:#28a745;font-weight:600">âœ… Required:</span><br>'
               + table_html(["Assumption","Meaning"],[
                   [bdg("Binary Y","red"),           txt_s("Outcome must be 0 or 1")],
                   [bdg("Linearity in logit","gold"), txt_s("log[P/(1-P)] linear in X")],
                   [bdg("Independence","blue"),       txt_s("Observations independent")],
                   [bdg("No multicollinearity","purple"),txt_s("VIF < 10 among predictors")],
                   [bdg("Events per var â‰¥10","orange"),txt_s("EPV rule: avoids overfitting")],
               ]), "green"),
            ib(f'<span style="color:#dc3545;-webkit-text-fill-color:#dc3545;font-weight:600">âŒ NOT Required (unlike OLS):</span><br>'
               + p(f'{rt2("Normal residuals")} â€” Bernoulli errors<br><br>'
                   f'{rt2("Homoscedasticity")} â€” Var varies with p<br><br>'
                   f'{rt2("Linear Y-X relationship")} â€” only logit linear<br><br>'
                   f'{rt2("Equal group sizes")} â€” handles imbalance'), "red"),
        )
    )
